import pandas as pd
import streamlit as st
import json
from src.models.food_over import FoodOverconsumptionScript
from config.app import SYSTEM_PROMPT_FILE, USER_PROMPT_FILE
from src.utils.logger import get_logger
from .data_models import Characters

logger = get_logger(__name__)


def display_json_debug(data, title="JSON Debug"):
    """JSONãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒãƒƒã‚°ç”¨ã«è¡¨ç¤º"""
    with st.expander(f"ğŸ” {title}", expanded=False):
        json_data = data.model_dump() if hasattr(data, "model_dump") else data
        st.json(json_data)


def display_search_results_debug(search_results):
    """æ¤œç´¢çµæœã‚’ãƒ‡ãƒãƒƒã‚°ç”¨ã«è¡¨ç¤º"""
    with st.expander("ğŸ” Tavilyæ¤œç´¢çµæœ", expanded=False):
        sections = [
            ("overeating", "é£Ÿã¹éãã«é–¢ã™ã‚‹æ¤œç´¢çµæœ"),
            ("benefits", "ãƒ¡ãƒªãƒƒãƒˆã«é–¢ã™ã‚‹æ¤œç´¢çµæœ"),
            ("disadvantages", "ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã«é–¢ã™ã‚‹æ¤œç´¢çµæœ"),
        ]

        for key, title in sections:
            st.subheader(title)
            if search_results.get(key):
                for i, content in enumerate(search_results[key], 1):
                    st.text_area(f"çµæœ {i}", content, height=100, key=f"{key}_{i}")
            else:
                st.info("æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


def display_scene_and_items_info(data: FoodOverconsumptionScript):
    """ã‚·ãƒ¼ãƒ³æƒ…å ±ã‚’è¡¨ç¤º"""
    st.markdown("### ğŸ¨ ã‚·ãƒ¼ãƒ³æƒ…å ±")

    if not data.sections:
        st.info("ã‚·ãƒ¼ãƒ³æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    section_scenes = {}

    for section in data.sections:
        section_scenes[section.section_name] = section.scene_background

    st.subheader("ğŸ¬ ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥ã‚·ãƒ¼ãƒ³")
    for section_name, scene in section_scenes.items():
        st.write(f"**{section_name}**: {scene}")


def display_prompt_file_status():
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®çŠ¶æ…‹ã‚’è¡¨ç¤º"""
    with st.expander("ğŸ“„ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š", expanded=False):
        files = [
            ("ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", SYSTEM_PROMPT_FILE),
            ("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", USER_PROMPT_FILE),
        ]

        for name, file_path in files:
            if file_path.exists():
                st.success(f"âœ… {name}: {file_path.stat().st_size} bytes")
            else:
                st.error(f"âŒ {name}: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")


def display_header(data: FoodOverconsumptionScript):
    """ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†ã®è¡¨ç¤º"""
    st.title(f"ğŸ¬ {data.title}")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("é£Ÿå“å", data.food_name)
    with col2:
        st.metric("æ¨å®šæ™‚é–“", data.estimated_duration)
    with col3:
        st.metric("ç·ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°", len(data.sections))


def get_character_emoji(character):
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã«å¯¾å¿œã™ã‚‹çµµæ–‡å­—ã‚’è¿”ã™"""
    emoji_map = {"zundamon": "ğŸŸ¢", "metan": "ğŸ”µ", "tsumugi": "ğŸŸ¡", "narrator": "ğŸ“¢"}
    return emoji_map.get(character, "ğŸ‘¤")


def get_expression_emoji(expression):
    """è¡¨æƒ…ã«å¯¾å¿œã™ã‚‹çµµæ–‡å­—ã‚’è¿”ã™"""
    expression_map = {
        "happy": "ğŸ˜Š",
        "excited": "ğŸ¤©",
        "worried": "ğŸ˜°",
        "thinking": "ğŸ¤”",
        "sad": "ğŸ˜¢",
        "surprised": "ğŸ˜²",
        "serious": "ğŸ˜",
        "normal": "ğŸ˜",
    }
    return expression_map.get(expression, "ğŸ˜")


def display_segment(segment, segment_index):
    """å€‹åˆ¥ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®è¡¨ç¤º"""
    character_emoji = get_character_emoji(segment.speaker)
    expression_emoji = get_expression_emoji(segment.expression)

    with st.container():
        col1, col2 = st.columns([1, 10])

        with col1:
            st.write(f"{character_emoji}")

        with col2:
            st.markdown(f"**{segment.speaker}** {expression_emoji}")
            st.markdown(f"ğŸ’¬ {segment.text}")

            if segment.visible_characters:
                st.caption(f"ğŸ‘¥ ç™»å ´: {', '.join(segment.visible_characters)}")


def display_section_overview(sections):
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¦‚è¦ã®è¡¨ç¤º"""
    st.subheader("ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¦‚è¦")

    section_data = [
        {
            "ã‚»ã‚¯ã‚·ãƒ§ãƒ³": f"{i+1}. {section.section_name}",
            "ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°": len(section.segments),
            "èƒŒæ™¯": section.scene_background,
        }
        for i, section in enumerate(sections)
    ]

    df = pd.DataFrame(section_data)
    st.dataframe(df, use_container_width=True, hide_index=True)


def display_character_stats(all_segments):
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼çµ±è¨ˆã®è¡¨ç¤º"""
    st.subheader("ğŸ‘¤ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼çµ±è¨ˆ")

    character_counts = {}
    expression_counts = {}

    for segment in all_segments:
        speaker = segment.speaker
        expression = segment.expression
        character_counts[speaker] = character_counts.get(speaker, 0) + 1
        expression_counts[expression] = expression_counts.get(expression, 0) + 1

    col1, col2 = st.columns(2)

    with col1:
        st.write("**ã‚»ãƒªãƒ•æ•°**")
        for char, count in sorted(
            character_counts.items(), key=lambda x: x[1], reverse=True
        ):
            st.write(f"{get_character_emoji(char)} {char}: {count}")

    with col2:
        st.write("**è¡¨æƒ…åˆ†å¸ƒ**")
        for expr, count in sorted(
            expression_counts.items(), key=lambda x: x[1], reverse=True
        ):
            st.write(f"{get_expression_emoji(expr)} {expr}: {count}")


def search_segments(all_segments, query):
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ¤œç´¢æ©Ÿèƒ½"""
    if not query:
        return all_segments

    query = query.lower()
    return [
        segment
        for segment in all_segments
        if any(
            query in str(getattr(segment, field, "")).lower()
            for field in ["text", "speaker", "expression"]
        )
    ]
