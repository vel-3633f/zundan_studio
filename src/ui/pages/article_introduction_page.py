import streamlit as st
import os
import json
import logging
from pathlib import Path
from typing import Dict, Optional, List, Any, Union
from src.models.food_over import FoodOverconsumptionScript
from src.utils.utils import process_conversation_segments

from dotenv import load_dotenv

load_dotenv()

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.exceptions import OutputParserException


# =============================================================================
# ãƒ­ã‚¬ãƒ¼è¨­å®š
# =============================================================================

# ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: INFOï¼‰
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å°‚ç”¨ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logger = logging.getLogger(__name__)
logger.setLevel(getattr(logging, LOG_LEVEL, logging.INFO))

# ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒæ—¢ã«è¿½åŠ ã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿è¿½åŠ 
if not logger.handlers:
    handler = logging.StreamHandler()
    handler.setFormatter(logging.Formatter(LOG_FORMAT))
    logger.addHandler(handler)


# =============================================================================
# è¨­å®šãƒ‡ãƒ¼ã‚¿
# =============================================================================

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®š
PROMPTS_DIR = Path("src/prompts")
SYSTEM_PROMPT_FILE = PROMPTS_DIR / "food_system_template.txt"
USER_PROMPT_FILE = PROMPTS_DIR / "food_user_template.txt"


class CharacterInfo:
    def __init__(self, name: str, display_name: str, personality: str):
        self.name = name
        self.display_name = display_name
        self.personality = personality


class ExpressionInfo:
    def __init__(self, name: str, display_name: str):
        self.name = name
        self.display_name = display_name


class BackgroundInfo:
    def __init__(self, name: str, display_name: str):
        self.name = name
        self.display_name = display_name


class ItemInfo:
    def __init__(self, name: str, display_name: str, emoji: str):
        self.name = name
        self.display_name = display_name
        self.emoji = emoji


class Characters:
    _characters = {
        "zundamon": CharacterInfo(
            "zundamon", "ãšã‚“ã ã‚‚ã‚“", "æ±åŒ—åœ°æ–¹ã®å¦–ç²¾ã€èªå°¾ã«ã€Œã€œã®ã ã€ã€Œã€œãªã®ã ã€"
        ),
        "metan": CharacterInfo("metan", "å››å›½ã‚ãŸã‚“", "ãƒ„ãƒƒã‚³ãƒŸå½¹ã€å¸¸è­˜çš„ã§å†·é™ãªæ€§æ ¼"),
        "tsumugi": CharacterInfo(
            "tsumugi", "æ˜¥æ—¥éƒ¨ã¤ã‚€ã", "ç´ æœ´ã§ç´”ç²‹ã€ç–‘å•ã‚’ã‚ˆãæŠ•ã’ã‹ã‘ã‚‹"
        ),
        "narrator": CharacterInfo("narrator", "ãƒŠãƒ¬ãƒ¼ã‚¿ãƒ¼", "å®¢è¦³çš„ã§è½ã¡ç€ã„ãŸè§£èª¬å½¹"),
    }

    @classmethod
    def get_character(cls, name: str) -> Optional[CharacterInfo]:
        return cls._characters.get(name)

    @classmethod
    def get_display_name(cls, name: str) -> str:
        char = cls._characters.get(name)
        return char.display_name if char else name


class Expressions:
    _expressions = {
        "normal": ExpressionInfo("normal", "é€šå¸¸"),
        "happy": ExpressionInfo("happy", "å–œã³"),
        "sad": ExpressionInfo("sad", "æ‚²ã—ã¿"),
        "angry": ExpressionInfo("angry", "æ€’ã‚Š"),
        "surprised": ExpressionInfo("surprised", "é©šã"),
        "thinking": ExpressionInfo("thinking", "è€ƒãˆä¸­"),
        "worried": ExpressionInfo("worried", "å¿ƒé…"),
        "excited": ExpressionInfo("excited", "èˆˆå¥®"),
        "sick": ExpressionInfo("sick", "ä½“èª¿ä¸è‰¯"),
    }

    @classmethod
    def get_display_name(cls, name: str) -> str:
        expr = cls._expressions.get(name)
        return expr.display_name if expr else name


class Backgrounds:
    _backgrounds = {
        "default": BackgroundInfo("default", "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"),
        "blue_sky": BackgroundInfo("blue_sky", "é’ç©º"),
        "sunset": BackgroundInfo("sunset", "å¤•ç„¼ã‘"),
        "night": BackgroundInfo("night", "å¤œ"),
        "forest": BackgroundInfo("forest", "æ£®"),
        "ocean": BackgroundInfo("ocean", "æµ·"),
        "sakura": BackgroundInfo("sakura", "æ¡œ"),
        "snow": BackgroundInfo("snow", "é›ª"),
        "kitchen": BackgroundInfo("kitchen", "ã‚­ãƒƒãƒãƒ³"),
        "hospital": BackgroundInfo("hospital", "ç—…é™¢"),
        "laboratory": BackgroundInfo("laboratory", "ç ”ç©¶å®¤"),
    }

    @classmethod
    def get_display_name(cls, name: str) -> str:
        bg = cls._backgrounds.get(name)
        return bg.display_name if bg else name


class Items:
    _items = {
        "none": ItemInfo("none", "ãªã—", ""),
        "coffee": ItemInfo("coffee", "ã‚³ãƒ¼ãƒ’ãƒ¼", "â˜•"),
        "tea": ItemInfo("tea", "ãŠèŒ¶", "ğŸµ"),
        "juice": ItemInfo("juice", "ã‚¸ãƒ¥ãƒ¼ã‚¹", "ğŸ¥¤"),
        "book": ItemInfo("book", "æœ¬", "ğŸ“š"),
        "notebook": ItemInfo("notebook", "ãƒãƒ¼ãƒˆ", "ğŸ“"),
        "pen": ItemInfo("pen", "ãƒšãƒ³", "âœ’ï¸"),
        "phone": ItemInfo("phone", "ã‚¹ãƒãƒ›", "ğŸ“±"),
        "food": ItemInfo("food", "é£Ÿã¹ç‰©", "ğŸ½ï¸"),
        "medicine": ItemInfo("medicine", "è–¬", "ğŸ’Š"),
        "magnifying_glass": ItemInfo("magnifying_glass", "è™«çœ¼é¡", "ğŸ”"),
    }

    @classmethod
    def get_item(cls, name: str) -> Optional[ItemInfo]:
        return cls._items.get(name)


_prompt_cache = {}


def load_prompt_from_file(file_path: Path, cache_key: str = None) -> str:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãï¼‰"""
    if cache_key and cache_key in _prompt_cache:
        logger.debug(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰: {cache_key}")
        return _prompt_cache[cache_key]

    try:
        if not file_path.exists():
            raise FileNotFoundError(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")

        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read().strip()

        if cache_key:
            _prompt_cache[cache_key] = content
            logger.debug(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜: {cache_key}")

        logger.info(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {file_path}")
        return content

    except Exception as e:
        error_msg = f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({file_path}): {str(e)}"
        logger.error(error_msg)


# =============================================================================
# è„šæœ¬ç”Ÿæˆé–¢æ•°
# =============================================================================


def generate_food_overconsumption_script(
    food_name: str, model: str = "gpt-4.1", temperature: float = 0.8
) -> Union[FoodOverconsumptionScript, Dict[str, Any]]:
    """é£Ÿã¹ç‰©æ‘‚å–éå¤šå‹•ç”»è„šæœ¬ã‚’ç”Ÿæˆã™ã‚‹"""
    logger.info(
        f"è„šæœ¬ç”Ÿæˆé–‹å§‹: é£Ÿã¹ç‰©={food_name}, ãƒ¢ãƒ‡ãƒ«={model}, temperature={temperature}"
    )

    try:
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            error_msg = "OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            logger.error(error_msg)
            return {
                "error": "API Key Error",
                "details": error_msg,
            }

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
        system_template = load_prompt_from_file(SYSTEM_PROMPT_FILE, "system")
        user_template = load_prompt_from_file(USER_PROMPT_FILE, "user")

        llm = ChatOpenAI(model=model, temperature=temperature, api_key=openai_api_key)
        parser = PydanticOutputParser(pydantic_object=FoodOverconsumptionScript)

        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", system_template),
                ("user", user_template),
            ]
        ).partial(format_instructions=parser.get_format_instructions())

        chain = prompt | llm | parser

        logger.info(f"{food_name}ã®æ‘‚å–éå¤šå‹•ç”»è„šæœ¬ã‚’LLMã§ç”Ÿæˆä¸­...")
        response_object = chain.invoke({"food_name": food_name})

        # all_segmentsã‚’ä½œæˆ
        all_segments = []
        for section in response_object.sections:
            all_segments.extend(section.segments)

        logger.info(f"LLMã‹ã‚‰å—ä¿¡ã—ãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(all_segments)}")

        # æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯ã¨åˆ†å‰²å‡¦ç†
        processed_segments = process_conversation_segments(all_segments)
        response_object.all_segments = processed_segments

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚‚æ›´æ–°
        segment_index = 0
        for section in response_object.sections:
            section_segments = []
            for _ in section.segments:
                if segment_index < len(processed_segments):
                    section_segments.append(processed_segments[segment_index])
                    segment_index += 1
            section.segments = section_segments

        logger.info("é£Ÿã¹ç‰©æ‘‚å–éå¤šå‹•ç”»è„šæœ¬ã®ç”Ÿæˆã«æˆåŠŸ")

        st.session_state.last_generated_json = response_object
        st.session_state.last_llm_output = "ãƒ‘ãƒ¼ã‚¹æˆåŠŸ: æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›æ¸ˆã¿"

        return response_object

    except OutputParserException as e:
        error_msg = "ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: LLMã®å‡ºåŠ›å½¢å¼ãŒä¸æ­£ã§ã™"
        logger.error(f"{error_msg}. LLMå‡ºåŠ›: {e.llm_output}")

        st.session_state.last_llm_output = e.llm_output
        st.session_state.last_generated_json = None

        return {
            "error": "Pydantic Parse Error",
            "details": str(e),
            "raw_output": e.llm_output,
        }
    except Exception as e:
        error_msg = f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        logger.error(error_msg, exc_info=True)

        st.session_state.last_llm_output = f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}"
        st.session_state.last_generated_json = None

        return {"error": "Unexpected Error", "details": str(e)}


# =============================================================================
# è¡¨ç¤ºãƒ»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =============================================================================


def display_json_debug(data: Any, title: str = "JSON Debug"):
    """JSONãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒãƒƒã‚°ç”¨ã«è¡¨ç¤ºã™ã‚‹"""
    with st.expander(f"ğŸ” {title}", expanded=False):
        if isinstance(data, (dict, list)):
            st.json(data)
        elif hasattr(data, "model_dump"):
            st.json(data.model_dump())
        else:
            try:
                json_str = json.dumps(data, indent=2, ensure_ascii=False)
                st.code(json_str, language="json")
            except Exception as e:
                logger.error(f"JSONå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
                st.text(f"JSONå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
                st.text(str(data))


def display_raw_llm_output(output: str, title: str = "LLM Raw Output"):
    """LLMã®ç”Ÿå‡ºåŠ›ã‚’è¡¨ç¤ºã™ã‚‹"""
    with st.expander(f"ğŸ¤– {title}", expanded=False):
        st.code(output, language="json")


def estimate_video_duration(segments: List[Dict]) -> str:
    """å‹•ç”»ã®æ¨å®šæ™‚é–“ã‚’è¨ˆç®—"""
    total_chars = sum(len(segment["text"]) for segment in segments)
    total_seconds = total_chars * 0.5
    minutes = int(total_seconds // 60)
    seconds = int(total_seconds % 60)
    duration = f"ç´„{minutes}åˆ†{seconds:02d}ç§’"
    logger.debug(f"å‹•ç”»æ™‚é–“æ¨å®š: {total_chars}æ–‡å­— â†’ {duration}")
    return duration


def display_food_script_preview(script_data: Union[FoodOverconsumptionScript, Dict]):
    """é£Ÿã¹ç‰©æ‘‚å–éå¤šå‹•ç”»è„šæœ¬ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤º"""
    if isinstance(script_data, FoodOverconsumptionScript):
        data = script_data.model_dump()
    else:
        data = script_data

    if not data or "all_segments" not in data:
        logger.warning("è¡¨ç¤ºã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ã§ã™")
        return

    st.subheader("ğŸ½ï¸ é£Ÿã¹ç‰©æ‘‚å–éå¤šå‹•ç”»è„šæœ¬ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

    # å‹•ç”»æƒ…å ±è¡¨ç¤º
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("YouTubeã‚¿ã‚¤ãƒˆãƒ«", data.get("title", "æœªè¨­å®š"))
    with col2:
        st.metric("å¯¾è±¡é£Ÿå“", data.get("food_name", "æœªè¨­å®š"))
    with col3:
        duration = data.get(
            "estimated_duration", estimate_video_duration(data["all_segments"])
        )
        st.metric("æ¨å®šæ™‚é–“", duration)
    with col4:
        st.metric("ç·ã‚»ãƒªãƒ•æ•°", len(data["all_segments"]))

    # ãƒ†ãƒ¼ãƒè¡¨ç¤º
    if "theme" in data:
        st.info(f"ğŸ¯ å‹•ç”»ãƒ†ãƒ¼ãƒ: {data['theme']}")

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥è¡¨ç¤º
    if "sections" in data:
        st.markdown("### ğŸ“‹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ§‹æˆ")
        for i, section in enumerate(data["sections"]):
            with st.expander(
                f"**{i+1}. {section['section_name']}** ({len(section['segments'])}ã‚»ãƒªãƒ•)",
                expanded=True,
            ):
                st.write(f"**ç›®çš„**: {section['purpose']}")

                for j, segment in enumerate(section["segments"]):
                    text_length = len(segment["text"])
                    length_color = "ğŸŸ¢" if text_length <= 30 else "ğŸ”´"

                    speaker_name = Characters.get_display_name(
                        segment.get("speaker", "unknown")
                    )
                    expression_name = Expressions.get_display_name(
                        segment.get("expression", "normal")
                    )

                    st.markdown(
                        f"**{j+1}. {speaker_name}** {expression_name} {length_color}({text_length}æ–‡å­—)"
                    )
                    st.write(f"ğŸ’¬ {segment['text']}")

                    # ã‚¢ã‚¤ãƒ†ãƒ ã¨èƒŒæ™¯æƒ…å ±
                    col_a, col_b = st.columns(2)
                    with col_a:
                        items = segment.get("character_items", {})
                        for char, item in items.items():
                            if item != "none":
                                item_info = Items.get_item(item)
                                if item_info:
                                    st.write(
                                        f"ğŸ“¦ {item_info.emoji} {item_info.display_name}"
                                    )

                    with col_b:
                        bg_name = segment.get("background", "default")
                        bg_display = Backgrounds.get_display_name(bg_name)
                        st.write(f"ğŸ–¼ï¸ {bg_display}")

                    if j < len(section["segments"]) - 1:
                        st.markdown("---")

    logger.info("è„šæœ¬ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºå®Œäº†")


def display_prompt_file_status():
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®çŠ¶æ…‹ã‚’è¡¨ç¤º"""
    with st.expander("ğŸ“„ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š", expanded=False):
        col1, col2 = st.columns(2)

        with col1:
            st.write("**ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**")
            if SYSTEM_PROMPT_FILE.exists():
                st.success(f"âœ… {SYSTEM_PROMPT_FILE}")
                file_size = SYSTEM_PROMPT_FILE.stat().st_size
                st.caption(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size} bytes")
                logger.debug(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª: {file_size} bytes")
            else:
                st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {SYSTEM_PROMPT_FILE}")
                logger.warning(
                    f"ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {SYSTEM_PROMPT_FILE}"
                )

        with col2:
            st.write("**ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**")
            if USER_PROMPT_FILE.exists():
                st.success(f"âœ… {USER_PROMPT_FILE}")
                file_size = USER_PROMPT_FILE.stat().st_size
                st.caption(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size} bytes")
                logger.debug(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª: {file_size} bytes")
            else:
                st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {USER_PROMPT_FILE}")
                logger.warning(
                    f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {USER_PROMPT_FILE}"
                )

        st.info("ğŸ’¡ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã™ã‚‹ã“ã¨ã§ã€AIã®å‹•ä½œã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™")


def display_debug_section():
    """ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤º"""
    if hasattr(st.session_state, "last_generated_json") or hasattr(
        st.session_state, "last_llm_output"
    ):
        st.subheader("ğŸ”§ ãƒ‡ãƒãƒƒã‚°æƒ…å ±")

        debug_mode = st.checkbox("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹ã«ã™ã‚‹", value=False)

        if debug_mode:
            logger.debug("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸ")

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«çŠ¶æ…‹è¡¨ç¤º
            display_prompt_file_status()

            if (
                hasattr(st.session_state, "last_generated_json")
                and st.session_state.last_generated_json
            ):
                display_json_debug(
                    st.session_state.last_generated_json,
                    "ç”Ÿæˆã•ã‚ŒãŸPydanticã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ",
                )

            if hasattr(st.session_state, "last_llm_output"):
                display_raw_llm_output(st.session_state.last_llm_output, "LLMã®ç”Ÿå‡ºåŠ›")


def add_conversation_to_session(conversation_data: Dict):
    """ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¿½åŠ """
    if "conversation_lines" not in st.session_state:
        st.session_state.conversation_lines = []

    # Foodå½¢å¼ã®è„šæœ¬ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
    segments = conversation_data.get("all_segments", [])

    for segment in segments:
        st.session_state.conversation_lines.append(
            {
                "speaker": segment["speaker"],
                "text": segment["text"],
                "expression": segment["expression"],
                "background": segment["background"],
                "visible_characters": segment["visible_characters"],
                "character_items": segment.get("character_items", {}),
            }
        )

    logger.info(f"ä¼šè©±ãƒªã‚¹ãƒˆã«{len(segments)}å€‹ã®ã‚»ãƒªãƒ•ã‚’è¿½åŠ ")
    st.success(f"ğŸ‰ {len(segments)}å€‹ã®ã‚»ãƒªãƒ•ã‚’ä¼šè©±ãƒªã‚¹ãƒˆã«è¿½åŠ ã—ã¾ã—ãŸï¼")
    st.info("ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã®ä¼šè©±å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ç¢ºèªã§ãã¾ã™ã€‚")


# =============================================================================
# ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸è¡¨ç¤ºé–¢æ•°
# =============================================================================


def render_food_overconsumption_page():
    """é£Ÿã¹ç‰©æ‘‚å–éå¤šè§£èª¬å‹•ç”»ç”Ÿæˆãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    logger.info("é£Ÿã¹ç‰©æ‘‚å–éå¤šè§£èª¬å‹•ç”»ç”Ÿæˆãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºé–‹å§‹")

    st.title("ğŸ½ï¸ é£Ÿã¹ç‰©æ‘‚å–éå¤šè§£èª¬å‹•ç”»ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼")
    st.markdown(
        "é£Ÿã¹ç‰©ã‚’é£Ÿã¹ã™ãã‚‹ã¨ã©ã†ãªã‚‹ã®ã‹ï¼Ÿã‚’ãƒ†ãƒ¼ãƒã«ã€ãšã‚“ã ã‚‚ã‚“ãŸã¡ãŒé¢ç™½ãè§£èª¬ã™ã‚‹å‹•ç”»è„šæœ¬ã‚’ä½œæˆã™ã‚‹ã®ã ã€œï¼"
    )

    # é£Ÿã¹ç‰©å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("ğŸ¥˜ èª¿ã¹ãŸã„é£Ÿã¹ç‰©ã‚’å…¥åŠ›")

    # äººæ°—ã®é£Ÿã¹ç‰©ä¾‹ã‚’è¡¨ç¤º
    st.markdown(
        "**äººæ°—ã®é£Ÿã¹ç‰©ä¾‹**: ãƒãƒ§ã‚³ãƒ¬ãƒ¼ãƒˆã€ã‚³ãƒ¼ãƒ’ãƒ¼ã€ãƒãƒŠãƒŠã€ãŠç±³ã€åµã€ç‰›ä¹³ã€ãƒ‘ãƒ³ã€ã‚¢ã‚¤ã‚¹ã‚¯ãƒªãƒ¼ãƒ ã€ãƒŠãƒƒãƒ„ã€ãŠèŒ¶ãªã©"
    )

    food_name = st.text_input(
        "é£Ÿã¹ç‰©åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        placeholder="ä¾‹: ãƒãƒ§ã‚³ãƒ¬ãƒ¼ãƒˆ",
        help="ä¸€èˆ¬çš„ãªé£Ÿã¹ç‰©ã‚„é£²ã¿ç‰©ã®åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã‚ˆã‚Šå…·ä½“çš„ãªåå‰ï¼ˆä¾‹ï¼šãƒ€ãƒ¼ã‚¯ãƒãƒ§ã‚³ãƒ¬ãƒ¼ãƒˆï¼‰ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚",
    )

    # ç”Ÿæˆè¨­å®š
    with st.expander("âš™ï¸ ç”Ÿæˆè¨­å®šï¼ˆè©³ç´°è¨­å®šï¼‰"):
        col1, col2 = st.columns(2)
        with col1:
            model = st.selectbox(
                "ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«",
                ["gpt-4.1", "gpt-4", "gpt-3.5-turbo"],
                index=0,
                help="gpt-4.1ãŒæœ€ã‚‚é«˜å“è³ªã§ã™ãŒã€å‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™",
            )
        with col2:
            temperature = st.slider(
                "å‰µé€ æ€§ãƒ¬ãƒ™ãƒ«",
                min_value=0.0,
                max_value=1.0,
                value=0.8,
                step=0.1,
                help="é«˜ã„ã»ã©å‰µé€ çš„ã ãŒã€ä¸€è²«æ€§ãŒä¸‹ãŒã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™",
            )

    # ç”Ÿæˆãƒœã‚¿ãƒ³
    if food_name and st.button("ğŸ¬ é£Ÿã¹ç‰©æ‘‚å–éå¤šè§£èª¬å‹•ç”»ã‚’ä½œæˆï¼", type="primary"):
        logger.info(f"å‹•ç”»ç”Ÿæˆãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã¾ã—ãŸ: é£Ÿã¹ç‰©={food_name}")

        with st.spinner(
            f"ğŸ¤– {food_name}ã®æ‘‚å–éå¤šè§£èª¬å‹•ç”»ã‚’ä½œæˆä¸­...ï¼ˆ30ç§’ã€œ1åˆ†ç¨‹åº¦ãŠå¾…ã¡ãã ã•ã„ï¼‰"
        ):
            result = generate_food_overconsumption_script(
                food_name, model=model, temperature=temperature
            )

            if isinstance(result, FoodOverconsumptionScript):
                logger.info("è„šæœ¬ç”ŸæˆæˆåŠŸã€ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤º")
                st.success("ğŸ‰ é£Ÿã¹ç‰©æ‘‚å–éå¤šè§£èª¬å‹•ç”»è„šæœ¬ãŒå®Œæˆã—ãŸã®ã ã€œï¼")
                display_food_script_preview(result)

                # JSONè¡¨ç¤º
                display_json_debug(result, "ç”Ÿæˆã•ã‚ŒãŸé£Ÿã¹ç‰©æ‘‚å–éå¤šè„šæœ¬ãƒ‡ãƒ¼ã‚¿")

                # ä¼šè©±ãƒªã‚¹ãƒˆã«è¿½åŠ ãƒœã‚¿ãƒ³
                if st.button("ğŸ“ ä¼šè©±ãƒªã‚¹ãƒˆã«è¿½åŠ ã™ã‚‹", type="secondary"):
                    add_conversation_to_session(result.model_dump())
            else:
                logger.error(f"è„šæœ¬ç”Ÿæˆå¤±æ•—: {result}")
                st.error(f"âŒ é£Ÿã¹ç‰©æ‘‚å–éå¤šè„šæœ¬ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

                error_details = result.get("details", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
                st.error(f"è©³ç´°: {error_details}")

                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯è¨­å®šæ–¹æ³•ã‚’æ¡ˆå†…
                if result.get("error") == "Prompt File Error":
                    st.info("ğŸ’¡ ä»¥ä¸‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™:")
                    st.code(f"- {SYSTEM_PROMPT_FILE}")
                    st.code(f"- {USER_PROMPT_FILE}")
                    st.info("ã“ã‚Œã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")

    # ãƒ‡ãƒãƒƒã‚°ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    display_debug_section()
