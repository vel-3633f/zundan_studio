"""ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²æ–¹å¼ã§ã®å°æœ¬ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""

import streamlit as st
from typing import Dict, List, Any, Union
from pathlib import Path

from src.models.food_over import FoodOverconsumptionScript, VideoSection, StoryOutline
from src.core.outline_generator import generate_outline
from src.core.section_generators.base import SectionGeneratorBase, SectionContext
from src.core.generate_food_over import (
    search_food_information,
    format_search_results_for_prompt,
    create_llm_instance
)
from config.models import get_model_config, get_default_model_config
from config.closing_section import create_closing_section
from src.utils.logger import get_logger

logger = get_logger(__name__)

# ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¨­å®š
SECTION_CONFIGS = [
    {"key": "hook", "name": "å†’é ­ãƒ•ãƒƒã‚¯ãƒ»å±æ©Ÿã®äºˆå‘Š", "min": 6, "max": 10, "fixed_background": None},
    {"key": "background", "name": "é£Ÿå“è§£èª¬ãƒ»èƒŒæ™¯æƒ…å ±", "min": 10, "max": 15, "fixed_background": "modern_study_room"},
    {"key": "daily", "name": "æ—¥å¸¸å°å…¥ãƒ»ç†ç”±ä»˜ã‘", "min": 12, "max": 18, "fixed_background": None},
    {"key": "honeymoon", "name": "æ¥½è¦³æœŸãƒ»ãƒãƒãƒ ãƒ¼ãƒ³æœŸ", "min": 15, "max": 25, "fixed_background": None},
    {"key": "deterioration", "name": "ç•°å¤‰æœŸãƒ»æ®µéšçš„æ‚ªåŒ–", "min": 25, "max": 35, "fixed_background": None},
    {"key": "crisis", "name": "å±æ©Ÿãƒ»è»¢æ©Ÿã¨ãªã‚‹æ±ºå®šçš„ã‚¤ãƒ™ãƒ³ãƒˆ", "min": 20, "max": 30, "fixed_background": None},
    {"key": "learning", "name": "çœŸç›¸è§£æ˜ãƒ»å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚º", "min": 15, "max": 25, "fixed_background": "library"},
    {"key": "recovery", "name": "å›å¾©ãƒ»æ–°ã—ã„ç¿’æ…£", "min": 10, "max": 20, "fixed_background": None},
]


def generate_outline_only(
    food_name: str,
    model: str = None,
    temperature: float = None
) -> Union[StoryOutline, Dict[str, Any]]:
    """ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã®ã¿ã‚’ç”Ÿæˆã™ã‚‹

    Args:
        food_name: é£Ÿã¹ç‰©å
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ID
        temperature: ç”Ÿæˆæ¸©åº¦

    Returns:
        StoryOutline: ç”Ÿæˆã•ã‚ŒãŸã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼è¾æ›¸
    """
    try:
        # ãƒ¢ãƒ‡ãƒ«è¨­å®š
        if model is None:
            model_config = get_default_model_config()
            model = model_config["id"]
        else:
            model_config = get_model_config(model)

        if temperature is None:
            temperature = model_config["default_temperature"]

        provider = model_config.get("provider", "openai")

        logger.info(
            f"ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆé–‹å§‹: é£Ÿã¹ç‰©={food_name}, "
            f"ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼={provider}, ãƒ¢ãƒ‡ãƒ«={model}, temperature={temperature}"
        )

        st.info("ğŸ” é£Ÿã¹ç‰©æƒ…å ±ã‚’æ¤œç´¢ä¸­...")
        search_results = search_food_information(food_name)
        reference_info = format_search_results_for_prompt(search_results)
        st.session_state.last_search_results = search_results

        st.info("ğŸ“‹ å…¨ä½“ã®ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‚’ä½œæˆä¸­...")
        llm = create_llm_instance(model, temperature, model_config)
        outline = generate_outline(food_name, reference_info, llm)

        # ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã¨é–¢é€£æƒ…å ±ã‚’session_stateã«ä¿å­˜
        st.session_state.current_outline = outline
        st.session_state.current_food_name = food_name
        st.session_state.current_reference_info = reference_info
        st.session_state.current_model = model
        st.session_state.current_temperature = temperature
        st.session_state.current_model_config = model_config

        st.success(f"âœ… ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆå®Œäº†: {outline.title}")
        logger.info(f"ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆå®Œäº†: {outline.title}")

        return outline

    except Exception as e:
        error_msg = f"ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"
        logger.error(error_msg, exc_info=True)
        st.error(f"âŒ ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return {"error": "Outline Generation Error", "details": str(e)}


def generate_sections_from_approved_outline() -> Union[FoodOverconsumptionScript, Dict[str, Any]]:
    """æ‰¿èªã•ã‚ŒãŸã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‹ã‚‰å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹

    Returns:
        FoodOverconsumptionScript: ç”Ÿæˆã•ã‚ŒãŸå°æœ¬ã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼è¾æ›¸
    """
    try:
        # session_stateã‹ã‚‰ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã¨è¨­å®šã‚’å–å¾—
        outline = st.session_state.current_outline
        food_name = st.session_state.current_food_name
        reference_info = st.session_state.current_reference_info
        model = st.session_state.current_model
        temperature = st.session_state.current_temperature
        model_config = st.session_state.current_model_config

        logger.info(f"æ‰¿èªã•ã‚ŒãŸã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‹ã‚‰è„šæœ¬ç”Ÿæˆé–‹å§‹: {outline.title}")

        llm = create_llm_instance(model, temperature, model_config)

        sections = []
        previous_sections_summary = []

        st.info("ğŸ¬ å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è©³ç´°ã‚’ç”Ÿæˆä¸­...")
        progress_bar = st.progress(0)
        status_text = st.empty()

        for i, config in enumerate(SECTION_CONFIGS):
            status_text.text(
                f"ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ {i+1}/8: {config['name']} ã‚’ç”Ÿæˆä¸­... "
                f"({config['min']}-{config['max']}ã‚»ãƒªãƒ•)"
            )

            generator = SectionGeneratorBase(
                section_key=config["key"],
                section_name=config["name"],
                min_lines=config["min"],
                max_lines=config["max"],
                fixed_background=config.get("fixed_background")
            )

            context = SectionContext(
                outline=outline,
                food_name=food_name,
                reference_information=reference_info,
                previous_sections=previous_sections_summary
            )

            try:
                section = generator.generate(context, llm)
                sections.append(section)

                section_summary = {
                    "section_name": section.section_name,
                    "segment_count": len(section.segments),
                    "last_speaker": section.segments[-1].speaker if section.segments else "",
                    "last_text": section.segments[-1].text if section.segments else "",
                    "summary": generator.summarize_section(section)
                }
                previous_sections_summary.append(section_summary)

                progress_bar.progress((i + 1) / len(SECTION_CONFIGS))

                with st.expander(
                    f"âœ… {config['name']} ({len(section.segments)}ã‚»ãƒªãƒ•)",
                    expanded=False
                ):
                    for seg in section.segments[:3]:
                        st.write(f"**{seg.speaker}**: {seg.text}")
                    if len(section.segments) > 3:
                        st.write(f"... ä»– {len(section.segments) - 3} ã‚»ãƒªãƒ•")

                logger.info(
                    f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ {i+1}/8 å®Œäº†: {config['name']} - "
                    f"{len(section.segments)}ã‚»ãƒªãƒ•"
                )

            except Exception as e:
                logger.error(f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼ ({config['name']}): {str(e)}", exc_info=True)
                st.error(f"âŒ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆå¤±æ•—: {config['name']}")
                return {
                    "error": "Section Generation Error",
                    "section": config['name'],
                    "details": str(e)
                }

        st.info("ğŸ” å“è³ªãƒã‚§ãƒƒã‚¯ä¸­...")

        all_segments = []
        for section in sections:
            all_segments.extend(section.segments)

        total_segments = len(all_segments)
        logger.info(f"å…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°ï¼ˆç· ã‚ããã‚Šå‰ï¼‰: {total_segments}")

        if total_segments < 130:
            st.warning(f"âš ï¸ ã‚»ãƒªãƒ•æ•°ãŒå°‘ãªã‚ã§ã™ï¼ˆ{total_segments}/130ï¼‰")
            logger.warning(f"ã‚»ãƒªãƒ•æ•°ãŒç›®æ¨™ã‚ˆã‚Šå°‘ãªã„: {total_segments}/130")
        elif total_segments > 160:
            st.warning(f"âš ï¸ ã‚»ãƒªãƒ•æ•°ãŒå¤šã‚ã§ã™ï¼ˆ{total_segments}/160ï¼‰")
            logger.warning(f"ã‚»ãƒªãƒ•æ•°ãŒç›®æ¨™ã‚ˆã‚Šå¤šã„: {total_segments}/160")
        else:
            st.success(f"âœ… ã‚»ãƒªãƒ•æ•°OK: {total_segments}ã‚»ãƒªãƒ•")
            logger.info(f"ã‚»ãƒªãƒ•æ•°ãŒé©æ­£ç¯„å›²: {total_segments}")

        with st.expander("ğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥ã‚»ãƒªãƒ•æ•°", expanded=False):
            for i, section in enumerate(sections):
                config = SECTION_CONFIGS[i]
                segment_count = len(section.segments)
                status = "âœ…" if config["min"] <= segment_count <= config["max"] else "âš ï¸"
                st.write(
                    f"{status} {section.section_name}: {segment_count}ã‚»ãƒªãƒ• "
                    f"(ç›®æ¨™: {config['min']}-{config['max']})"
                )

        # ç· ã‚ããã‚Šã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
        st.info("ğŸ¬ ç· ã‚ããã‚Šã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ä¸­...")
        closing_section = create_closing_section()
        sections.append(closing_section)
        all_segments.extend(closing_section.segments)

        total_segments_with_closing = len(all_segments)
        logger.info(
            f"ç· ã‚ããã‚Šã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ å®Œäº†: +{len(closing_section.segments)}ã‚»ãƒªãƒ• "
            f"(åˆè¨ˆ: {total_segments_with_closing})"
        )
        st.success(f"âœ… ç· ã‚ããã‚Šè¿½åŠ : +{len(closing_section.segments)}ã‚»ãƒªãƒ•")

        estimated_duration_sec = total_segments_with_closing * 4
        estimated_duration = f"{estimated_duration_sec // 60}åˆ†{estimated_duration_sec % 60}ç§’"

        script = FoodOverconsumptionScript(
            title=outline.title,
            food_name=food_name,
            estimated_duration=estimated_duration,
            sections=sections,
            all_segments=all_segments
        )

        st.session_state.last_generated_json = script
        st.session_state.last_llm_output = f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²æ–¹å¼ã§ç”ŸæˆæˆåŠŸ: {total_segments_with_closing}ã‚»ãƒªãƒ•"

        st.success("ğŸ‰ å°æœ¬ç”Ÿæˆå®Œäº†ï¼")
        logger.info(f"å°æœ¬ç”ŸæˆæˆåŠŸ: {total_segments_with_closing}ã‚»ãƒªãƒ•, æ¨å®šæ™‚é–“: {estimated_duration}")

        return script

    except Exception as e:
        error_msg = f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        logger.error(error_msg, exc_info=True)

        st.session_state.last_llm_output = f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}"
        st.session_state.last_generated_json = None

        return {"error": "Unexpected Error", "details": str(e)}


def generate_food_overconsumption_script_sectioned(
    food_name: str,
    model: str = None,
    temperature: float = None
) -> Union[FoodOverconsumptionScript, Dict[str, Any]]:
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²æ–¹å¼ã§é£Ÿã¹ç‰©æ‘‚å–éå¤šå‹•ç”»è„šæœ¬ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆãƒ¯ãƒ³ã‚¹ãƒ†ãƒƒãƒ—ç‰ˆãƒ»å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹å­˜ï¼‰

    Args:
        food_name: é£Ÿã¹ç‰©å
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ID
        temperature: ç”Ÿæˆæ¸©åº¦

    Returns:
        FoodOverconsumptionScript: ç”Ÿæˆã•ã‚ŒãŸå°æœ¬ã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼è¾æ›¸
    """
    # ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆ
    outline_result = generate_outline_only(food_name, model, temperature)

    if isinstance(outline_result, dict) and "error" in outline_result:
        return outline_result

    # ãã®ã¾ã¾æ‰¿èªã—ã¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
    return generate_sections_from_approved_outline()
