from typing import Dict, List, Any, Union, Optional, Callable
from pathlib import Path

from app.models.food_over import FoodOverconsumptionScript, VideoSection, StoryOutline
from app.core.script_generators.outline_generator import generate_outline
from app.core.section_generators.base import SectionGeneratorBase, SectionContext
from app.core.script_generators.generate_food_over import (
    search_food_information,
    format_search_results_for_prompt,
    create_llm_instance
)
from app.config.models import get_model_config, get_default_model_config
from app.config.content_config.closing_section import create_closing_section
from app.utils_legacy.logger import get_logger

logger = get_logger(__name__)

# ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¨­å®š
SECTION_CONFIGS = [
    {"key": "hook", "name": "å†’é ­ãƒ•ãƒƒã‚¯ãƒ»å±æ©Ÿã®äºˆå‘Š", "min": 6, "max": 10, "background": "home_livingroom_morning"},
    {"key": "background", "name": "é£Ÿå“è§£èª¬ãƒ»èƒŒæ™¯æƒ…å ±", "min": 10, "max": 15, "background": "modern_study_room"},
    {"key": "daily", "name": "æ—¥å¸¸å°å…¥ãƒ»ç†ç”±ä»˜ã‘", "min": 12, "max": 18, "background": "cafe_counter_morning"},
    {"key": "honeymoon", "name": "æ¥½è¦³æœŸãƒ»ãƒãƒãƒ ãƒ¼ãƒ³æœŸ", "min": 15, "max": 25, "background": "restaurant_ikinaristeak_day"},
    {"key": "deterioration", "name": "ç•°å¤‰æœŸãƒ»æ®µéšçš„æ‚ªåŒ–", "min": 25, "max": 35, "background": "home_livingroom_morning"},
    {"key": "crisis", "name": "å±æ©Ÿãƒ»è»¢æ©Ÿã¨ãªã‚‹æ±ºå®šçš„ã‚¤ãƒ™ãƒ³ãƒˆ", "min": 20, "max": 30, "background": "office_meeting_emergency"},
    {"key": "learning", "name": "çœŸç›¸è§£æ˜ãƒ»å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚º", "min": 15, "max": 25, "background": "library"},
    {"key": "recovery", "name": "å›å¾©ãƒ»æ–°ã—ã„ç¿’æ…£", "min": 10, "max": 20, "background": "home_livingroom_morning"},
]


def generate_outline_only(
    food_name: str,
    model: str = None,
    temperature: float = None,
    progress_callback: Optional[Callable[[str], None]] = None
) -> Union[StoryOutline, Dict[str, Any]]:
    """ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã®ã¿ã‚’ç”Ÿæˆã™ã‚‹

    Args:
        food_name: é£Ÿã¹ç‰©å
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ID
        temperature: ç”Ÿæˆæ¸©åº¦
        progress_callback: é€²æ—é€šçŸ¥ç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°

    Returns:
        StoryOutline: ç”Ÿæˆã•ã‚ŒãŸã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼è¾æ›¸
    """
    try:
        # ãƒ¢ãƒ‡ãƒ«è¨­å®š
        if model is None:
            model_config = get_default_model_config()
            model = model_config["id"]
        else:
            model_config = get_model_config(model)

        if temperature is None:
            temperature = model_config["default_temperature"]

        provider = model_config.get("provider", "openai")

        logger.info(
            f"ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆé–‹å§‹: é£Ÿã¹ç‰©={food_name}, "
            f"ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼={provider}, ãƒ¢ãƒ‡ãƒ«={model}, temperature={temperature}"
        )

        if progress_callback:
            progress_callback("ğŸ” é£Ÿã¹ç‰©æƒ…å ±ã‚’æ¤œç´¢ä¸­...")
        search_results = search_food_information(food_name)
        reference_info = format_search_results_for_prompt(search_results)

        if progress_callback:
            progress_callback("ğŸ“‹ å…¨ä½“ã®ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‚’ä½œæˆä¸­...")
        llm = create_llm_instance(model, temperature, model_config)
        outline = generate_outline(food_name, reference_info, llm)

        logger.info(f"ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆå®Œäº†: {outline.title}")

        # è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸ã¨ã—ã¦è¿”ã™
        return {
            "outline": outline,
            "search_results": search_results,
            "reference_info": reference_info,
            "model": model,
            "temperature": temperature,
            "model_config": model_config
        }

    except Exception as e:
        error_msg = f"ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"
        logger.error(error_msg, exc_info=True)
        return {"error": "Outline Generation Error", "details": str(e)}


def generate_sections_from_approved_outline(
    outline: StoryOutline,
    food_name: str,
    reference_info: str,
    model: str,
    temperature: float,
    model_config: Dict[str, Any],
    progress_callback: Optional[Callable[[str, float], None]] = None
) -> Union[FoodOverconsumptionScript, Dict[str, Any]]:
    """æ‰¿èªã•ã‚ŒãŸã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‹ã‚‰å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹

    Args:
        outline: æ‰¿èªã•ã‚ŒãŸã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³
        food_name: é£Ÿã¹ç‰©å
        reference_info: å‚ç…§æƒ…å ±
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ID
        temperature: ç”Ÿæˆæ¸©åº¦
        model_config: ãƒ¢ãƒ‡ãƒ«è¨­å®š
        progress_callback: é€²æ—é€šçŸ¥ç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°(message, progress)

    Returns:
        FoodOverconsumptionScript: ç”Ÿæˆã•ã‚ŒãŸå°æœ¬ã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼è¾æ›¸
    """
    try:
        logger.info(f"æ‰¿èªã•ã‚ŒãŸã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‹ã‚‰è„šæœ¬ç”Ÿæˆé–‹å§‹: {outline.title}")

        llm = create_llm_instance(model, temperature, model_config)

        sections = []
        previous_sections_summary = []

        if progress_callback:
            progress_callback("ğŸ¬ å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è©³ç´°ã‚’ç”Ÿæˆä¸­...", 0.0)

        for i, config in enumerate(SECTION_CONFIGS):
            if progress_callback:
                progress_callback(
                    f"ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ {i+1}/8: {config['name']} ã‚’ç”Ÿæˆä¸­... "
                    f"({config['min']}-{config['max']}ã‚»ãƒªãƒ•)",
                    (i / len(SECTION_CONFIGS))
                )

            generator = SectionGeneratorBase(
                section_key=config["key"],
                section_name=config["name"],
                min_lines=config["min"],
                max_lines=config["max"],
                fixed_background=config.get("background")
            )

            context = SectionContext(
                outline=outline,
                food_name=food_name,
                reference_information=reference_info,
                previous_sections=previous_sections_summary
            )

            try:
                section = generator.generate(context, llm)
                sections.append(section)

                section_summary = {
                    "section_name": section.section_name,
                    "segment_count": len(section.segments),
                    "last_speaker": section.segments[-1].speaker if section.segments else "",
                    "last_text": section.segments[-1].text if section.segments else "",
                    "summary": generator.summarize_section(section)
                }
                previous_sections_summary.append(section_summary)

                if progress_callback:
                    progress_callback(
                        f"âœ… {config['name']} å®Œäº† ({len(section.segments)}ã‚»ãƒªãƒ•)",
                        ((i + 1) / len(SECTION_CONFIGS))
                    )

                logger.info(
                    f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ {i+1}/8 å®Œäº†: {config['name']} - "
                    f"{len(section.segments)}ã‚»ãƒªãƒ•"
                )

            except Exception as e:
                logger.error(f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼ ({config['name']}): {str(e)}", exc_info=True)
                return {
                    "error": "Section Generation Error",
                    "section": config['name'],
                    "details": str(e)
                }

        if progress_callback:
            progress_callback("ğŸ” å“è³ªãƒã‚§ãƒƒã‚¯ä¸­...", 0.9)

        all_segments = []
        for section in sections:
            all_segments.extend(section.segments)

        total_segments = len(all_segments)
        logger.info(f"å…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°ï¼ˆç· ã‚ããã‚Šå‰ï¼‰: {total_segments}")

        if total_segments < 130:
            logger.warning(f"ã‚»ãƒªãƒ•æ•°ãŒç›®æ¨™ã‚ˆã‚Šå°‘ãªã„: {total_segments}/130")
        elif total_segments > 160:
            logger.warning(f"ã‚»ãƒªãƒ•æ•°ãŒç›®æ¨™ã‚ˆã‚Šå¤šã„: {total_segments}/160")
        else:
            logger.info(f"ã‚»ãƒªãƒ•æ•°ãŒé©æ­£ç¯„å›²: {total_segments}")

        # ç· ã‚ããã‚Šã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
        if progress_callback:
            progress_callback("ğŸ¬ ç· ã‚ããã‚Šã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ä¸­...", 0.95)
        closing_section = create_closing_section()
        sections.append(closing_section)
        all_segments.extend(closing_section.segments)

        total_segments_with_closing = len(all_segments)
        logger.info(
            f"ç· ã‚ããã‚Šã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ å®Œäº†: +{len(closing_section.segments)}ã‚»ãƒªãƒ• "
            f"(åˆè¨ˆ: {total_segments_with_closing})"
        )

        estimated_duration_sec = total_segments_with_closing * 4
        estimated_duration = f"{estimated_duration_sec // 60}åˆ†{estimated_duration_sec % 60}ç§’"

        script = FoodOverconsumptionScript(
            title=outline.title,
            food_name=food_name,
            estimated_duration=estimated_duration,
            sections=sections,
            all_segments=all_segments
        )

        if progress_callback:
            progress_callback("ğŸ‰ å°æœ¬ç”Ÿæˆå®Œäº†ï¼", 1.0)
        logger.info(f"å°æœ¬ç”ŸæˆæˆåŠŸ: {total_segments_with_closing}ã‚»ãƒªãƒ•, æ¨å®šæ™‚é–“: {estimated_duration}")

        return script

    except Exception as e:
        error_msg = f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        logger.error(error_msg, exc_info=True)
        return {"error": "Unexpected Error", "details": str(e)}


def generate_food_overconsumption_script_sectioned(
    food_name: str,
    model: str = None,
    temperature: float = None,
    progress_callback: Optional[Callable[[str, float], None]] = None
) -> Union[FoodOverconsumptionScript, Dict[str, Any]]:
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²æ–¹å¼ã§é£Ÿã¹ç‰©æ‘‚å–éå¤šå‹•ç”»è„šæœ¬ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆãƒ¯ãƒ³ã‚¹ãƒ†ãƒƒãƒ—ç‰ˆãƒ»å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹å­˜ï¼‰

    Args:
        food_name: é£Ÿã¹ç‰©å
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ID
        temperature: ç”Ÿæˆæ¸©åº¦
        progress_callback: é€²æ—é€šçŸ¥ç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°

    Returns:
        FoodOverconsumptionScript: ç”Ÿæˆã•ã‚ŒãŸå°æœ¬ã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼è¾æ›¸
    """
    # ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆ
    outline_result = generate_outline_only(food_name, model, temperature, progress_callback)

    if isinstance(outline_result, dict) and "error" in outline_result:
        return outline_result

    # çµæœã‹ã‚‰å¿…è¦ãªæƒ…å ±ã‚’å–å¾—
    outline = outline_result["outline"]
    reference_info = outline_result["reference_info"]
    model = outline_result["model"]
    temperature = outline_result["temperature"]
    model_config = outline_result["model_config"]

    # ãã®ã¾ã¾æ‰¿èªã—ã¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
    return generate_sections_from_approved_outline(
        outline, food_name, reference_info, model, temperature, model_config, progress_callback
    )
